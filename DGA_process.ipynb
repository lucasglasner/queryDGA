{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "from process import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:19<00:00,  6.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process runoff spreadsheets given in path\n",
    "variable  = 'AlturayCaudalInstantaneo'\n",
    "region    = 7\n",
    "raw_paths = glob(f'tmp/{variable}/{region}/*.xls') # <--- PATH\n",
    "# raw_paths = glob(f'/home/lucas/PROYECTOS/En Proceso/A032445-Kimal Lo Aguirre 2/3_Aplicabilidad_PAS_156_Torres/2_Hidrologia/Datos Estaciones/Caudales/Rio Illapel en el Peral/*.xls')\n",
    "data     = []\n",
    "metadata = []\n",
    "names    = []\n",
    "for p in tqdm.tqdm(raw_paths, total=len(raw_paths)):\n",
    "    df = pd.read_excel(p)\n",
    "    ts, mdata = process_DGAtable(df, variable)\n",
    "    data.append(ts['q_m3s'])\n",
    "    names.append(ts.name)\n",
    "    metadata.append(mdata)\n",
    "data = pd.concat(data, keys=names).drop_duplicates().unstack().T.sort_index()\n",
    "metadata = pd.concat(metadata, axis=1)\n",
    "metadata = metadata.loc[:,~metadata.columns.duplicated()].copy().T\n",
    "\n",
    "# metadata.to_csv(f'data/{variable}/{region}-Region_MetadataEstaciones.csv')\n",
    "# data.to_csv(f'data/{variable}/{region}-Region_{variable}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/72 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:03<00:00, 22.06it/s]\n"
     ]
    }
   ],
   "source": [
    "variable = 'PrecipitacionesMaximasEn24Horas'\n",
    "# region   = 2\n",
    "region = 12\n",
    "raw_paths = glob(f'tmp/{variable}/{region}/*.xls')\n",
    "data     = []\n",
    "metadata = []\n",
    "for p in tqdm.tqdm(raw_paths, total=len(raw_paths)):\n",
    "    df = pd.read_excel(p)\n",
    "    ts, mdata = process_DGAtable(df, variable)\n",
    "    ts.index = ts.index.year\n",
    "    data.append(ts)\n",
    "    metadata.append(mdata)\n",
    "    # del df, ts, mdata\n",
    "data = pd.concat(data, axis=1)\n",
    "metadata = pd.concat(metadata, axis=1)\n",
    "metadata = metadata.loc[:,~metadata.columns.duplicated()].copy()\n",
    "\n",
    "ncols    = []\n",
    "mult_st  = []\n",
    "for st in metadata.columns:\n",
    "    x = data[st].dropna(how='all')\n",
    "    if len(pd.DataFrame(x).columns)>1:\n",
    "        ncol = [x.iloc[:,i].dropna() for i in range(len(x.columns))]\n",
    "        ncols.append(pd.concat(ncol,axis=0).drop_duplicates())\n",
    "        mult_st.append(st)\n",
    "        del ncol\n",
    "    del x\n",
    "ncols = pd.concat(ncols, axis=1).reindex(data.index)\n",
    "data  = pd.concat([data.drop(mult_st, axis=1), ncols], axis=1).sort_index()\n",
    "metadata.T.to_csv(f'data/{variable}/{region}-Region_MetadataEstaciones.csv')\n",
    "data.to_csv(f'data/{variable}/{region}-Region_{variable}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_coordinates(x):\n",
    "    coord  = x.split(' ')\n",
    "    num    = float(coord[0].replace('°',''))\n",
    "    minute = float(coord[1].replace(\"'\",\"\"))/60\n",
    "    second = float(coord[2].replace(\"''\",\"\"))/60/60\n",
    "    return -(num+minute+second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "variable = 'PrecipitacionesMaximasEn24Horas'\n",
    "metadata_paths = glob(f'data/{variable}/*Metadata*.csv')\n",
    "data_paths     = glob(f'data/{variable}/*{variable}*.csv')\n",
    "\n",
    "metadata = [pd.read_csv(m, index_col=0) for m in metadata_paths]\n",
    "metadata = pd.concat(metadata, axis=0).drop_duplicates()\n",
    "metadata['lon'] = metadata['lon'].map(lambda x: transform_coordinates(x))\n",
    "metadata['lat'] = metadata['lat'].map(lambda x: transform_coordinates(x))\n",
    "metadata = metadata[metadata.Cuenca != 'ISLAS DEL PACIFICO']\n",
    "\n",
    "data = [pd.read_csv(m, index_col=0, parse_dates=False) for m in data_paths]\n",
    "data = pd.concat(data, axis=1)\n",
    "data = data[metadata.index]\n",
    "\n",
    "metadata_shape = gpd.GeoDataFrame(geometry=gpd.points_from_xy(metadata.lon, metadata.lat),\n",
    "                                  crs='epsg:4326').to_crs('epsg:32719')\n",
    "metadata_shape.index = metadata.index\n",
    "\n",
    "metadata['x'] = metadata_shape.geometry.x\n",
    "metadata['y'] = metadata_shape.geometry.y\n",
    "metadata_shape = pd.concat([metadata,metadata_shape], axis=1).set_geometry('geometry')\n",
    "\n",
    "data.to_csv(f'data/DATA_{variable}.csv')\n",
    "metadata.to_csv(f'data/MetadataEstaciones_{variable}.csv')\n",
    "metadata_shape.to_file(f'data/MetadataEstaciones_{variable}.gpkg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "river",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
